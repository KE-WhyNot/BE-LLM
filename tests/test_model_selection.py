#!/usr/bin/env python3
"""
ëª¨ë¸ ì„ íƒ ìµœì í™” í…ŒìŠ¤íŠ¸
Gemini 2.0 vs GPT-4o ì„±ëŠ¥ ë¹„êµ ë° ì‘ì—…ë³„ ìµœì  ëª¨ë¸ ì„ íƒ ê²€ì¦
"""

import os
import time
from app.services.langgraph_enhanced.model_selector import (
    ModelSelector, 
    TaskType, 
    select_model_for_task, 
    get_task_type_from_query
)


def test_model_selection():
    """ëª¨ë¸ ì„ íƒ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ¤– ëª¨ë¸ ì„ íƒ ìµœì í™” í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ëª¨ë¸ ì„ íƒê¸° ì´ˆê¸°í™”
    model_selector = ModelSelector()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        {
            "query": "ì‚¼ì„±ì „ì ì£¼ê°€ ì•Œë ¤ì¤˜",
            "expected_task": TaskType.KOREAN_FINANCE,
            "expected_model": "gemini-2.0-flash-exp",
            "reason": "í•œêµ­ ê¸ˆìœµ ìš©ì–´ íŠ¹í™”"
        },
        {
            "query": "PERì´ ë­ì•¼?",
            "expected_task": TaskType.KOREAN_FINANCE,
            "expected_model": "gemini-2.0-flash-exp", 
            "reason": "í•œêµ­ ê¸ˆìœµ ê°œë… ì„¤ëª…"
        },
        {
            "query": "ì‚¼ì„±ì „ì ê¸°ìˆ ì  ë¶„ì„ê³¼ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì¢…í•©í•´ì„œ íˆ¬ì ì˜ê²¬ì„ ì•Œë ¤ì¤˜",
            "expected_task": TaskType.COMPLEX_ANALYSIS,
            "expected_model": "gemini-2.0-flash-exp",
            "reason": "ê¸´ ì»¨í…ìŠ¤íŠ¸ì™€ ë³µì¡í•œ ë¶„ì„"
        },
        {
            "query": "Pythonìœ¼ë¡œ ì£¼ê°€ ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” ì½”ë“œë¥¼ ë§Œë“¤ì–´ì¤˜",
            "expected_task": TaskType.CODE_GENERATION,
            "expected_model": "gpt-4o",
            "reason": "ì½”ë“œ ìƒì„± ì •í™•ë„"
        },
        {
            "query": "ì•ˆë…•í•˜ì„¸ìš”",
            "expected_task": TaskType.SIMPLE_QUERY,
            "expected_model": "gemini-2.0-flash-exp",
            "reason": "ë¹ ë¥¸ ì‘ë‹µê³¼ ì €ë ´í•œ ë¹„ìš©"
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(test_queries, 1):
        print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}: {test_case['reason']}")
        print(f"ğŸ” ì¿¼ë¦¬: {test_case['query']}")
        print(f"ğŸ¯ ì˜ˆìƒ ì‘ì—… ìœ í˜•: {test_case['expected_task'].value}")
        print(f"ğŸ¯ ì˜ˆìƒ ëª¨ë¸: {test_case['expected_model']}")
        print("-" * 50)
        
        # ì‘ì—… ìœ í˜• ì¶”ì¶œ
        detected_task_type = get_task_type_from_query(test_case['query'])
        
        # ëª¨ë¸ ì„ íƒ
        selected_model = select_model_for_task(
            detected_task_type, 
            test_case['query'],
            {"language": "ko", "complexity": "moderate"}
        )
        
        # ëª¨ë¸ ì¶”ì²œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        recommendation = model_selector.get_model_recommendation(detected_task_type)
        
        print(f"ğŸ” ê°ì§€ëœ ì‘ì—… ìœ í˜•: {detected_task_type.value}")
        print(f"ğŸ¤– ì„ íƒëœ ëª¨ë¸: {selected_model}")
        print(f"ğŸ’¡ ì¶”ì²œ ëª¨ë¸: {recommendation['recommended']}")
        print(f"ğŸ“ ì¶”ì²œ ì´ìœ : {recommendation['reason']}")
        print(f"ğŸ”„ ëŒ€ì•ˆ ëª¨ë¸: {recommendation['alternative']}")
        
        # ì •í™•ë„ í‰ê°€
        task_correct = detected_task_type == test_case['expected_task']
        model_correct = selected_model == test_case['expected_model']
        
        if task_correct and model_correct:
            print("âœ… ì™„ë²½í•œ ë§¤ì¹­!")
            test_result = "ì„±ê³µ"
        elif task_correct or model_correct:
            print("âš ï¸ ë¶€ë¶„ ë§¤ì¹­")
            test_result = "ë¶€ë¶„ì„±ê³µ"
        else:
            print("âŒ ë§¤ì¹­ ì‹¤íŒ¨")
            test_result = "ì‹¤íŒ¨"
        
        results.append({
            "test_case": test_case,
            "detected_task": detected_task_type,
            "selected_model": selected_model,
            "recommendation": recommendation,
            "task_correct": task_correct,
            "model_correct": model_correct,
            "test_result": test_result
        })
        
        print("-" * 50)
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ‰ ëª¨ë¸ ì„ íƒ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 50)
    
    successful_tests = sum(1 for r in results if r['test_result'] == "ì„±ê³µ")
    partial_tests = sum(1 for r in results if r['test_result'] == "ë¶€ë¶„ì„±ê³µ")
    failed_tests = sum(1 for r in results if r['test_result'] == "ì‹¤íŒ¨")
    total_tests = len(results)
    
    print(f"ğŸ“Š ì„±ê³µë¥ : {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)")
    print(f"âš ï¸ ë¶€ë¶„ì„±ê³µ: {partial_tests}/{total_tests}")
    print(f"âŒ ì‹¤íŒ¨: {failed_tests}/{total_tests}")
    
    # ì‘ì—… ìœ í˜•ë³„ ì •í™•ë„
    task_accuracy = sum(1 for r in results if r['task_correct']) / total_tests * 100
    model_accuracy = sum(1 for r in results if r['model_correct']) / total_tests * 100
    
    print(f"ğŸ¯ ì‘ì—… ìœ í˜• ì •í™•ë„: {task_accuracy:.1f}%")
    print(f"ğŸ¯ ëª¨ë¸ ì„ íƒ ì •í™•ë„: {model_accuracy:.1f}%")
    
    # ëª¨ë¸ë³„ ì„ íƒ ë¹ˆë„
    model_counts = {}
    for result in results:
        model = result['selected_model']
        model_counts[model] = model_counts.get(model, 0) + 1
    
    print(f"\nğŸ“ˆ ëª¨ë¸ë³„ ì„ íƒ ë¹ˆë„:")
    for model, count in model_counts.items():
        percentage = count / total_tests * 100
        print(f"   {model}: {count}íšŒ ({percentage:.1f}%)")
    
    # ì„±ëŠ¥ ë¹„êµ ë¶„ì„
    print(f"\nâš¡ ì„±ëŠ¥ ë¹„êµ ë¶„ì„:")
    print("   Gemini 2.0 Flash:")
    print("   âœ… í•œêµ­ì–´ ê¸ˆìœµ ìš©ì–´ íŠ¹í™”")
    print("   âœ… ë¹ ë¥¸ ì‘ë‹µ ì†ë„ (1ì´ˆ ì´ë‚´)")
    print("   âœ… ì €ë ´í•œ ë¹„ìš© (ë¬´ë£Œ í• ë‹¹ëŸ‰ ë§ìŒ)")
    print("   âœ… ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (1M í† í°)")
    
    print("\n   GPT-4o:")
    print("   âœ… ë†’ì€ ì •í™•ë„")
    print("   âœ… ì•ˆì •ì ì¸ ì„±ëŠ¥")
    print("   âš ï¸ ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼ (2-3ì´ˆ)")
    print("   âš ï¸ ë†’ì€ ë¹„ìš©")
    
    print(f"\nğŸ¯ ê¶Œì¥ì‚¬í•­:")
    print("   â€¢ í•œêµ­ ê¸ˆìœµ ì±—ë´‡: Gemini 2.0 Flash ìš°ì„  ì‚¬ìš©")
    print("   â€¢ ë³µì¡í•œ ë¶„ì„: Gemini 2.0 Flash (ê¸´ ì»¨í…ìŠ¤íŠ¸ í™œìš©)")
    print("   â€¢ ì½”ë“œ ìƒì„±: GPT-4o (ì •í™•ë„ ì¤‘ì‹œ)")
    print("   â€¢ ë‹¨ìˆœ ì§ˆë¬¸: Gemini 2.0 Flash (ì†ë„ì™€ ë¹„ìš©)")


if __name__ == "__main__":
    test_model_selection()

"""
LLM ê´€ë¦¬ì (Gemini 2.0 Flash ì „ìš©)
ê¹”ë”í•˜ê²Œ Geminië§Œ ì‚¬ìš©í•˜ë„ë¡ ë‹¨ìˆœí™”
"""

from typing import Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from app.config import settings


class LLMManager:
    """LLM ê´€ë¦¬ì (Gemini ì „ìš©)"""
    
    def __init__(self):
        self.llm_cache = {}
        self.default_model = "gemini-2.0-flash-exp"
    
    def get_llm(self, 
                model_name: Optional[str] = None, 
                temperature: float = 0.7, 
                **kwargs) -> ChatGoogleGenerativeAI:
        """
        Gemini LLM ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ìºì‹± í¬í•¨)
        """
        # ëª¨ë¸ëª…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
        if model_name is None:
            model_name = self.default_model
        
        # ìºì‹œì—ì„œ í™•ì¸
        cache_key = f"{model_name}_{temperature}_{hash(str(kwargs))}"
        if cache_key in self.llm_cache:
            return self.llm_cache[cache_key]
        
        # API í‚¤ í™•ì¸
        google_api_key = settings.google_api_key
        if not google_api_key:
            raise ValueError("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Gemini LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        llm = ChatGoogleGenerativeAI(
            model=model_name,
            temperature=temperature,
            google_api_key=google_api_key,
            **kwargs
        )
        
        # ìºì‹œì— ì €ì¥
        self.llm_cache[cache_key] = llm
        
        print(f"ğŸ¤– Gemini LLM ë¡œë“œ: {model_name} (temperature: {temperature})")
        return llm
    
    def get_default_llm(self, temperature: float = 0.7, **kwargs) -> ChatGoogleGenerativeAI:
        """ê¸°ë³¸ Gemini LLM ë°˜í™˜"""
        return self.get_llm(model_name=None, temperature=temperature, **kwargs)
    
    def clear_cache(self):
        """LLM ìºì‹œ ì´ˆê¸°í™”"""
        self.llm_cache.clear()
        print("ğŸ§¹ LLM ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ì „ì—­ LLM ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
llm_manager = LLMManager()


def get_gemini_llm(model_name: Optional[str] = None, 
                   temperature: float = 0.7, 
                   **kwargs) -> ChatGoogleGenerativeAI:
    """Gemini LLM ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (í¸ì˜ í•¨ìˆ˜)"""
    return llm_manager.get_llm(model_name, temperature, **kwargs)


def get_default_gemini_llm(temperature: float = 0.7, **kwargs) -> ChatGoogleGenerativeAI:
    """ê¸°ë³¸ Gemini LLM ë°˜í™˜ (í¸ì˜ í•¨ìˆ˜)"""
    return llm_manager.get_default_llm(temperature, **kwargs)

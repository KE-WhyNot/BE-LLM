"""ì„¹í„°ë³„ ë‰´ìŠ¤ ì „ë§ ë¶„ì„ ì„œë¹„ìŠ¤"""

import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone
from app.services.workflow_components.news_service import NewsService
from app.services.workflow_components.mk_rss_scraper import MKKnowledgeGraphService
from app.services.langgraph_enhanced.agents.news_agent import NewsAgent
from langchain_google_genai import ChatGoogleGenerativeAI
from app.config import settings


class SectorAnalysisService:
    """ì„¹í„°ë³„ ë‰´ìŠ¤ ë¶„ì„ ë° ì „ë§ í‰ê°€ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.news_service = NewsService()
        self.mk_kg_service = MKKnowledgeGraphService()
        self.news_agent = NewsAgent()
        self.llm = self._initialize_llm()
        
        # ì„¹í„° í‚¤ì›Œë“œ ë§¤í•‘
        self.sector_keywords = {
            "í™”í•™": ["í™”í•™", "chemical", "petrochemical", "specialty chemical"],
            "ì œì•½": ["ì œì•½", "pharmaceutical", "biotech", "drug development", "medicine"],
            "ì „ê¸°Â·ì „ì": ["ë°˜ë„ì²´", "semiconductor", "electronics", "chip", "memory", "display"],
            "ìš´ì†¡ì¥ë¹„Â·ë¶€í’ˆ": ["ìë™ì°¨", "automobile", "automotive", "electric vehicle", "EV", "battery"],
            "ê¸°íƒ€ê¸ˆìœµ": ["ê¸ˆìœµ", "banking", "financial", "insurance", "fintech"],
            "ê¸°ê³„Â·ì¥ë¹„": ["ê¸°ê³„", "machinery", "equipment", "industrial equipment"],
            "ê¸ˆì†": ["ì² ê°•", "steel", "metal", "aluminum", "copper"],
            "ê±´ì„¤": ["ê±´ì„¤", "construction", "infrastructure", "real estate"],
            "IT ì„œë¹„ìŠ¤": ["IT", "software", "platform", "cloud", "AI", "technology"]
        }
        
        # ì „ë§ í‰ê°€ í‚¤ì›Œë“œ
        self.positive_keywords = [
            "ì„±ì¥", "ì¦ê°€", "ìƒìŠ¹", "í˜¸ì „", "ê°œì„ ", "í™•ëŒ€", "ê¸ì •", "ê¸°ëŒ€", "íšŒë³µ", "ì•ˆì •",
            "growth", "increase", "rise", "improvement", "expansion", "positive", "optimistic"
        ]
        
        self.negative_keywords = [
            "í•˜ë½", "ê°ì†Œ", "ì•…í™”", "ì¶•ì†Œ", "ë¶€ì •", "ìš°ë ¤", "ìœ„í—˜", "ë‘”í™”", "ë³€ë™ì„±",
            "decline", "decrease", "deterioration", "negative", "concern", "risk", "volatility"
        ]
    
    def _initialize_llm(self):
        """LLM ì´ˆê¸°í™”"""
        if settings.google_api_key:
            return ChatGoogleGenerativeAI(
                model="gemini-2.0-flash-exp",
                temperature=0.3,
                google_api_key=settings.google_api_key
            )
        return None
    
    async def analyze_sector_outlook(
        self, 
        sector: str, 
        time_range: str = "week"
    ) -> Dict[str, Any]:
        """ì„¹í„°ë³„ ì „ë§ ë¶„ì„"""
        
        try:
            print(f"ğŸ“Š {sector} ì„¹í„° ì „ë§ ë¶„ì„ ì‹œì‘...")
            
            # 1. ì„¹í„° ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘
            news_data = await self._collect_sector_news(sector, time_range)
            
            if not news_data:
                return self._get_neutral_outlook(sector)
            
            # 2. ë‰´ìŠ¤ ë¶„ì„ ë° ì „ë§ í‰ê°€
            outlook_analysis = await self._analyze_news_sentiment(news_data, sector)
            
            # 3. ê²°ê³¼ ì¢…í•©
            sector_outlook = {
                "sector": sector,
                "analysis_time": datetime.now(timezone.utc).isoformat(),
                "news_count": len(news_data),
                "sentiment_score": outlook_analysis.get("sentiment_score", 0),
                "outlook": outlook_analysis.get("outlook", "ì¤‘ë¦½"),
                "key_factors": outlook_analysis.get("key_factors", []),
                "confidence": outlook_analysis.get("confidence", 0.5),
                "summary": outlook_analysis.get("summary", ""),
                "weight_adjustment": self._calculate_weight_adjustment(
                    outlook_analysis.get("sentiment_score", 0)
                )
            }
            
            print(f"âœ… {sector} ì„¹í„° ë¶„ì„ ì™„ë£Œ: {sector_outlook['outlook']} (ì‹ ë¢°ë„: {sector_outlook['confidence']:.2f})")
            return sector_outlook
            
        except Exception as e:
            print(f"âŒ {sector} ì„¹í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_neutral_outlook(sector)
    
    async def _collect_sector_news(self, sector: str, time_range: str) -> List[Dict[str, Any]]:
        """ì„¹í„° ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        
        keywords = self.sector_keywords.get(sector, [sector])
        all_news = []
        
        # ê° í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰
        for keyword in keywords[:2]:  # ìƒìœ„ 2ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
            try:
                # í•œê¸€ í‚¤ì›Œë“œëŠ” ë§¤ì¼ê²½ì œì—ì„œ, ì˜ë¬¸ í‚¤ì›Œë“œëŠ” Google RSSì—ì„œ
                if any(ord(char) >= 0xAC00 and ord(char) <= 0xD7AF for char in keyword):
                    # í•œê¸€ í‚¤ì›Œë“œ - ë§¤ì¼ê²½ì œ ê²€ìƒ‰
                    mk_news = await self.mk_kg_service.search_news(
                        query=keyword, 
                        limit=3
                    )
                    for news in mk_news:
                        news['source'] = 'mk_rss'
                        all_news.append(news)
                else:
                    # ì˜ë¬¸ í‚¤ì›Œë“œ - Google RSS ê²€ìƒ‰
                    google_news = await self.news_service.get_comprehensive_news(
                        query=keyword,
                        use_google_rss=True,
                        translate=True
                    )
                    all_news.extend(google_news[:3])
                
                # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                await asyncio.sleep(0.5)
                
            except Exception as e:
                print(f"âš ï¸ {keyword} ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        # ì¤‘ë³µ ì œê±° ë° ìµœì‹ ìˆœ ì •ë ¬
        unique_news = self._remove_duplicate_news(all_news)
        return unique_news[:10]  # ìµœëŒ€ 10ê°œ
    
    async def _analyze_news_sentiment(
        self, 
        news_data: List[Dict[str, Any]], 
        sector: str
    ) -> Dict[str, Any]:
        """ë‰´ìŠ¤ ê°ì • ë¶„ì„ ë° ì „ë§ í‰ê°€ (íŒŒì¥ ì˜ˆìƒ í¬í•¨)"""
        
        if not self.llm:
            return self._fallback_sentiment_analysis(news_data, sector)
        
        # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        news_texts = []
        for news in news_data:
            title = news.get('title', '')
            summary = news.get('summary', news.get('content', ''))
            published = news.get('published', '')
            source = news.get('source', 'Unknown')
            news_texts.append(f"[{source}] {title}\në‚´ìš©: {summary}\në°œí–‰: {published}")
        
        combined_text = "\n\n".join(news_texts[:5])  # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ë§Œ ë¶„ì„
        
        # ê°•í™”ëœ LLM í”„ë¡¬í”„íŠ¸ (íŒŒì¥ ì˜ˆìƒ í¬í•¨)
        prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. {sector} ì„¹í„° ê´€ë ¨ ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì—¬ ì‹œì¥ ì „ë§ê³¼ ì˜ˆìƒë˜ëŠ” íŒŒì¥ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

=== ë‰´ìŠ¤ ë‚´ìš© ===
{combined_text}

=== ë¶„ì„ ìš”ì²­ ===
ìœ„ ë‰´ìŠ¤ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

sentiment_score: [ê°ì • ì ìˆ˜ -1.0(ë§¤ìš° ë¶€ì •) ~ +1.0(ë§¤ìš° ê¸ì •)]
outlook: [ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì  ì¤‘ í•˜ë‚˜]
confidence: [ì‹ ë¢°ë„ 0.0 ~ 1.0 (ë‰´ìŠ¤ì˜ ì‹ ë¢°ì„±ê³¼ ì¼ê´€ì„± ê³ ë ¤)]
key_factors: ["ìš”ì¸1", "ìš”ì¸2", "ìš”ì¸3"]
market_impact: [ì˜ˆìƒë˜ëŠ” ì‹œì¥ íŒŒì¥ê³¼ ì˜í–¥ ë²”ìœ„ ì„¤ëª…]
time_horizon: [ë‹¨ê¸°(1-3ê°œì›”)/ì¤‘ê¸°(3-12ê°œì›”)/ì¥ê¸°(1ë…„ ì´ìƒ) ì¤‘ ì£¼ìš” ì˜í–¥ ê¸°ê°„]
risk_factors: ["ë¦¬ìŠ¤í¬1", "ë¦¬ìŠ¤í¬2"]
opportunity_factors: ["ê¸°íšŒ1", "ê¸°íšŒ2"]
summary: [íˆ¬ìì ê´€ì ì—ì„œì˜ í•µì‹¬ ìš”ì•½ (2-3ë¬¸ì¥)]

=== ë¶„ì„ ê¸°ì¤€ ===
1. ë‰´ìŠ¤ì˜ ì‹ ë¢°ì„±: ì¶œì²˜ì™€ ë‚´ìš©ì˜ êµ¬ì²´ì„± í‰ê°€
2. ì‹œì¥ íŒŒì¥: í•´ë‹¹ ì„¹í„°ë¿ë§Œ ì•„ë‹ˆë¼ ì—°ê´€ ì‚°ì—…ì— ë¯¸ì¹  ì˜í–¥
3. ì‹œì ë³„ ì˜í–¥: ë‹¨ê¸° vs ì¤‘ì¥ê¸° ê´€ì  êµ¬ë¶„
4. íˆ¬ì ê´€ì : ì‹¤ì œ íˆ¬ì ê²°ì •ì— ë„ì›€ì´ ë˜ëŠ” êµ¬ì²´ì  ê·¼ê±°

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”."""

        try:
            response = await self.llm.ainvoke(prompt)
            return self._parse_enhanced_sentiment_response(response.content, sector, news_data)
        except Exception as e:
            print(f"âš ï¸ LLM ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._fallback_sentiment_analysis(news_data, sector)
    
    def _parse_enhanced_sentiment_response(
        self, 
        response_text: str, 
        sector: str, 
        news_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ê°•í™”ëœ LLM ì‘ë‹µ íŒŒì‹± (íŒŒì¥ ì˜ˆìƒ í¬í•¨)"""
        
        result = {
            "sentiment_score": 0.0,
            "outlook": "ì¤‘ë¦½ì ",
            "confidence": 0.5,
            "key_factors": [],
            "market_impact": f"{sector} ì„¹í„°ì— ëŒ€í•œ ëª…í™•í•œ ì˜í–¥ ë¶„ì„ì´ ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤.",
            "time_horizon": "ì¤‘ê¸°",
            "risk_factors": [],
            "opportunity_factors": [],
            "summary": f"{sector} ì„¹í„° ì „ë§ ë¶„ì„ ê²°ê³¼",
            "news_sources": len(news_data),
            "analysis_depth": "enhanced"
        }
        
        try:
            lines = response_text.strip().split('\n')
            
            for line in lines:
                line = line.strip()
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip().lower()
                    value = value.strip()
                    
                    if 'sentiment_score' in key:
                        try:
                            score = float(value)
                            result["sentiment_score"] = max(-1.0, min(1.0, score))
                        except:
                            pass
                    elif 'outlook' in key:
                        if value in ["ê¸ì •ì ", "ì¤‘ë¦½ì ", "ë¶€ì •ì "]:
                            result["outlook"] = value
                    elif 'confidence' in key:
                        try:
                            conf = float(value)
                            result["confidence"] = max(0.0, min(1.0, conf))
                        except:
                            pass
                    elif 'market_impact' in key:
                        result["market_impact"] = value
                    elif 'time_horizon' in key:
                        if any(t in value for t in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]):
                            result["time_horizon"] = value
                    elif 'summary' in key:
                        result["summary"] = value
                    elif any(factor_key in key for factor_key in ['key_factors', 'risk_factors', 'opportunity_factors']):
                        # ë°°ì—´ íŒŒì‹±
                        factors = self._parse_array_field(value)
                        if 'key_factors' in key:
                            result["key_factors"] = factors[:3]
                        elif 'risk_factors' in key:
                            result["risk_factors"] = factors[:2]
                        elif 'opportunity_factors' in key:
                            result["opportunity_factors"] = factors[:2]
            
            # ì‹ ë¢°ë„ ì¶”ê°€ ê²€ì¦ (ë‰´ìŠ¤ í’ˆì§ˆ ê³ ë ¤)
            result["confidence"] = self._adjust_confidence_by_news_quality(
                result["confidence"], news_data
            )
            
        except Exception as e:
            print(f"âš ï¸ ê°•í™”ëœ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return result
    
    def _parse_array_field(self, value: str) -> List[str]:
        """ë°°ì—´ í˜•íƒœ í•„ë“œ íŒŒì‹±"""
        try:
            # ëŒ€ê´„í˜¸ ì œê±° í›„ ì‰¼í‘œë¡œ ë¶„í• 
            if '[' in value and ']' in value:
                clean_value = value.replace('[', '').replace(']', '').replace('"', '')
                items = [item.strip() for item in clean_value.split(',')]
                return [item for item in items if item]
            else:
                return [value] if value else []
        except:
            return [value] if value else []
    
    def _adjust_confidence_by_news_quality(
        self, 
        base_confidence: float, 
        news_data: List[Dict[str, Any]]
    ) -> float:
        """ë‰´ìŠ¤ í’ˆì§ˆì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •"""
        
        if not news_data:
            return 0.3
        
        quality_factors = []
        
        for news in news_data:
            source = news.get('source', '')
            title_length = len(news.get('title', ''))
            content_length = len(news.get('summary', news.get('content', '')))
            
            # ì¶œì²˜ë³„ ê°€ì¤‘ì¹˜
            if 'mk' in source.lower() or 'maeil' in source.lower():
                quality_factors.append(0.9)  # ë§¤ì¼ê²½ì œ ë†’ì€ ì‹ ë¢°ë„
            elif 'google' in source.lower():
                quality_factors.append(0.7)  # Google RSS ì¤‘ê°„ ì‹ ë¢°ë„
            else:
                quality_factors.append(0.5)
            
            # ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€
            if title_length > 10 and content_length > 50:
                quality_factors.append(0.8)
            elif title_length > 5 and content_length > 20:
                quality_factors.append(0.6)
            else:
                quality_factors.append(0.4)
        
        avg_quality = sum(quality_factors) / len(quality_factors) if quality_factors else 0.5
        
        # ê¸°ë³¸ ì‹ ë¢°ë„ì™€ ë‰´ìŠ¤ í’ˆì§ˆì„ ê²°í•©
        adjusted_confidence = (base_confidence * 0.7) + (avg_quality * 0.3)
        
        return max(0.2, min(0.9, adjusted_confidence))
    
    def _fallback_sentiment_analysis(
        self, 
        news_data: List[Dict[str, Any]], 
        sector: str
    ) -> Dict[str, Any]:
        """í´ë°± ê°ì • ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        
        positive_count = 0
        negative_count = 0
        total_count = 0
        
        for news in news_data:
            text = f"{news.get('title', '')} {news.get('summary', '')}".lower()
            
            pos_matches = sum(1 for keyword in self.positive_keywords if keyword in text)
            neg_matches = sum(1 for keyword in self.negative_keywords if keyword in text)
            
            positive_count += pos_matches
            negative_count += neg_matches
            total_count += len(text.split())
        
        # ì ìˆ˜ ê³„ì‚°
        if positive_count + negative_count == 0:
            sentiment_score = 0.0
            outlook = "ì¤‘ë¦½ì "
        else:
            sentiment_score = (positive_count - negative_count) / max(positive_count + negative_count, 1)
            if sentiment_score > 0.2:
                outlook = "ê¸ì •ì "
            elif sentiment_score < -0.2:
                outlook = "ë¶€ì •ì "
            else:
                outlook = "ì¤‘ë¦½ì "
        
        return {
            "sentiment_score": sentiment_score,
            "outlook": outlook,
            "confidence": min(0.7, (positive_count + negative_count) / 10),
            "key_factors": [f"{sector} ê´€ë ¨ ë‰´ìŠ¤ ë™í–¥"],
            "summary": f"{sector} ì„¹í„°ëŠ” {outlook} ì „ë§ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤."
        }
    
    def _calculate_weight_adjustment(self, sentiment_score: float) -> float:
        """ê°ì • ì ìˆ˜ë¥¼ ë¹„ì¤‘ ì¡°ì •ê°’ìœ¼ë¡œ ë³€í™˜"""
        
        # -1.0 ~ +1.0 ì ìˆ˜ë¥¼ -15% ~ +15% ì¡°ì •ê°’ìœ¼ë¡œ ë³€í™˜
        max_adjustment = 15
        adjustment = sentiment_score * max_adjustment
        
        # -15% ~ +15% ë²”ìœ„ë¡œ ì œí•œ
        return max(-15, min(15, adjustment))
    
    def _remove_duplicate_news(self, news_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ë‰´ìŠ¤ ì œê±°"""
        
        seen_titles = set()
        unique_news = []
        
        for news in news_list:
            title = news.get('title', '').strip().lower()
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_news.append(news)
        
        return unique_news
    
    def _get_neutral_outlook(self, sector: str) -> Dict[str, Any]:
        """ì¤‘ë¦½ì  ì „ë§ ë°˜í™˜ (ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ)"""
        
        return {
            "sector": sector,
            "analysis_time": datetime.now(timezone.utc).isoformat(),
            "news_count": 0,
            "sentiment_score": 0.0,
            "outlook": "ì¤‘ë¦½ì ",
            "key_factors": ["ì¶©ë¶„í•œ ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ"],
            "confidence": 0.3,
            "summary": f"{sector} ì„¹í„°ì˜ ìµœì‹  ì „ë§ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
            "weight_adjustment": 0.0
        }
    
    async def analyze_multiple_sectors(
        self, 
        sectors: List[str], 
        time_range: str = "week"
    ) -> Dict[str, Dict[str, Any]]:
        """ì—¬ëŸ¬ ì„¹í„° ë™ì‹œ ë¶„ì„"""
        
        print(f"ğŸ“Š {len(sectors)}ê°œ ì„¹í„° ì „ë§ ë¶„ì„ ì‹œì‘...")
        
        # ë™ì‹œ ë¶„ì„ (ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ 3ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬)
        results = {}
        
        for i in range(0, len(sectors), 3):
            batch_sectors = sectors[i:i+3]
            
            # ë°°ì¹˜ë³„ ë™ì‹œ ì‹¤í–‰
            tasks = [
                self.analyze_sector_outlook(sector, time_range) 
                for sector in batch_sectors
            ]
            
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for sector, result in zip(batch_sectors, batch_results):
                if isinstance(result, Exception):
                    print(f"âŒ {sector} ë¶„ì„ ì‹¤íŒ¨: {result}")
                    results[sector] = self._get_neutral_outlook(sector)
                else:
                    results[sector] = result
            
            # ë°°ì¹˜ ê°„ ë”œë ˆì´
            if i + 3 < len(sectors):
                await asyncio.sleep(2)
        
        print(f"âœ… ì„¹í„° ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ")
        return results


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
sector_analysis_service = SectorAnalysisService()

"""
ê¸ˆìœµ RAG (Retrieval-Augmented Generation) ì„œë¹„ìŠ¤

ì—­í• : ChromaDB ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ ë° ê¸ˆìœµ ì§€ì‹ ê²€ìƒ‰ (ìˆœìˆ˜ RAG)
- ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ë° ê´€ë¦¬
- ë¬¸ì„œ ì¶”ê°€ (knowledge_base_serviceì—ì„œ í˜¸ì¶œ)
- ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰
- ì§€ì‹ ì¿¼ë¦¬ ì²˜ë¦¬ ("PERì´ ë­ì•¼?" ë“±)
"""

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from typing import List


class FinancialRAGService:
    """ê¸ˆìœµ RAG ì„œë¹„ìŠ¤ - ë²¡í„° ê²€ìƒ‰ ì „ìš©"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        """
        RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            persist_directory: ChromaDB ì €ì¥ ê²½ë¡œ
        """
        self.persist_directory = persist_directory
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'}
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        self.vectorstore = None
        self._initialize_vectorstore()
    
    def _initialize_vectorstore(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings
            )
            print("âœ… ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings
            )
            print("âœ… ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    def add_financial_documents(self, documents: List[Document]):
        """
        ê¸ˆìœµ ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        
        í˜¸ì¶œ ìœ„ì¹˜: knowledge_base_service.pyì˜ build_from_data_directory()
        
        Args:
            documents: LangChain Document ë¦¬ìŠ¤íŠ¸
        """
        if not documents:
            print("âš ï¸ ì¶”ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë¬¸ì„œ ë¶„í• 
        split_docs = self.text_splitter.split_documents(documents)
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        self.vectorstore.add_documents(split_docs)
        print(f"âœ… {len(split_docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
    
    def search_relevant_documents(self, query: str, k: int = 5) -> List[Document]:
        """
        ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            
        Returns:
            List[Document]: ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ kê°œ ë¬¸ì„œ
        """
        if not self.vectorstore:
            print("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            docs = self.vectorstore.similarity_search(query, k=k)
            print(f"ğŸ” '{query}'ì— ëŒ€í•´ {len(docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return docs
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_context_for_query(self, query: str) -> str:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„± (knowledge ì¿¼ë¦¬ìš©)
        
        í˜¸ì¶œ ìœ„ì¹˜: financial_workflow.pyì˜ _search_knowledge()
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸ (ì˜ˆ: "PERì´ ë­ì•¼?", "ë¶„ì‚°íˆ¬ìë€?")
            
        Returns:
            str: ê´€ë ¨ ê¸ˆìœµ ì§€ì‹ ì»¨í…ìŠ¤íŠ¸
        """
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.search_relevant_documents(query, k=3)
        
        context_parts = []
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©
        if relevant_docs:
            context_parts.append("ğŸ“š ê´€ë ¨ ê¸ˆìœµ ì§€ì‹:")
            for i, doc in enumerate(relevant_docs, 1):
                content = doc.page_content[:500]  # ìµœëŒ€ 500ì
                context_parts.append(f"\n{i}. {content}...")
        else:
            context_parts.append("âš ï¸ ê´€ë ¨ ê¸ˆìœµ ì§€ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return "\n".join(context_parts)


# ì „ì—­ RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
rag_service = FinancialRAGService()

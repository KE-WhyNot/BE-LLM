"""
ê¸ˆìœµ RAG (Retrieval-Augmented Generation) ì„œë¹„ìŠ¤

ì—­í• : ChromaDB ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ ë° ê¸ˆìœµ ì§€ì‹ ê²€ìƒ‰ (ìˆœìˆ˜ RAG)
- ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ë° ê´€ë¦¬
- ë¬¸ì„œ ì¶”ê°€ (knowledge_base_serviceì—ì„œ í˜¸ì¶œ)
- ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰
- ì§€ì‹ ì¿¼ë¦¬ ì²˜ë¦¬ ("PERì´ ë­ì•¼?" ë“±)
"""

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from typing import List, Optional
from app.config import settings
from app.utils.common_utils import get_config_manager


class FinancialRAGService:
    """ê¸ˆìœµ RAG ì„œë¹„ìŠ¤ - ë²¡í„° ê²€ìƒ‰ ì „ìš©"""
    
    def __init__(self, persist_directory: Optional[str] = None):
        """
        RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            persist_directory: ChromaDB ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
        """
        self.persist_directory = persist_directory or settings.chroma_persist_directory
        
        # ê³µí†µ ì„¤ì • ì‚¬ìš©
        config_manager = get_config_manager()
        rag_settings = config_manager.get_rag_settings()
        chunk_settings = config_manager.get_chunk_settings()
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=config_manager.get_embedding_model(),
            model_kwargs={'device': 'cpu'}
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_settings['chunk_size'],
            chunk_overlap=chunk_settings['chunk_overlap'],
            length_function=len,
        )
        self.max_search_results = rag_settings['max_search_results']
        self.vectorstore = None
        self._initialize_vectorstore()
    
    def _initialize_vectorstore(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings
            )
            print("âœ… ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings
            )
            print("âœ… ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    def add_financial_documents(self, documents: List[Document]):
        """
        ê¸ˆìœµ ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        
        í˜¸ì¶œ ìœ„ì¹˜: knowledge_base_service.pyì˜ build_from_data_directory()
        
        Args:
            documents: LangChain Document ë¦¬ìŠ¤íŠ¸
        """
        if not documents:
            print("âš ï¸ ì¶”ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë¬¸ì„œ ë¶„í• 
        split_docs = self.text_splitter.split_documents(documents)
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        self.vectorstore.add_documents(split_docs)
        print(f"âœ… {len(split_docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
    
    def search_relevant_documents(self, query: str, k: Optional[int] = None) -> List[Document]:
        """
        ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜ (Noneì´ë©´ ì„¤ì •ê°’ ì‚¬ìš©)
            
        Returns:
            List[Document]: ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ kê°œ ë¬¸ì„œ
        """
        if k is None:
            k = self.max_search_results
            
        if not self.vectorstore:
            print("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            docs = self.vectorstore.similarity_search(query, k=k)
            print(f"ğŸ” '{query}'ì— ëŒ€í•´ {len(docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return docs
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_context_for_query(self, query: str) -> str:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„± (knowledge ì¿¼ë¦¬ìš©)
        
        í˜¸ì¶œ ìœ„ì¹˜: financial_workflow.pyì˜ _search_knowledge()
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸ (ì˜ˆ: "PERì´ ë­ì•¼?", "ë¶„ì‚°íˆ¬ìë€?")
            
        Returns:
            str: ê´€ë ¨ ê¸ˆìœµ ì§€ì‹ ì»¨í…ìŠ¤íŠ¸
        """
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.search_relevant_documents(query, k=3)
        
        context_parts = []
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©
        if relevant_docs:
            context_parts.append("ğŸ“š ê´€ë ¨ ê¸ˆìœµ ì§€ì‹:")
            for i, doc in enumerate(relevant_docs, 1):
                content = doc.page_content[:500]  # ìµœëŒ€ 500ì
                context_parts.append(f"\n{i}. {content}...")
        else:
            context_parts.append("âš ï¸ ê´€ë ¨ ê¸ˆìœµ ì§€ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return "\n".join(context_parts)


# ì „ì—­ RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
rag_service = FinancialRAGService()

"""ë‰´ìŠ¤ ì¡°íšŒ ì„œë¹„ìŠ¤ (ë™ì  í”„ë¡¬í”„íŒ… ì§€ì› + ë§¤ì¼ê²½ì œ RSS + Google RSS ë²ˆì—­ í†µí•©)"""

import asyncio
from typing import List, Dict, Any
from langchain_google_genai import ChatGoogleGenerativeAI
from app.config import settings
from app.services.workflow_components.data_agent_service import NewsCollector
from app.services.workflow_components.mk_rss_scraper import MKKnowledgeGraphService, search_mk_news
from app.services.workflow_components.google_rss_translator import google_rss_translator, search_google_news
from app.utils.stock_utils import get_company_name_from_symbol
# prompt_managerëŠ” agents/ì—ì„œ ê°œë³„ ê´€ë¦¬


class NewsService:
    """ê¸ˆìœµ ë‰´ìŠ¤ ì¡°íšŒë¥¼ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤ (í†µí•© ë‰´ìŠ¤ ì„œë¹„ìŠ¤)
    
    ë‰´ìŠ¤ ì†ŒìŠ¤:
    1. ë§¤ì¼ê²½ì œ RSS + Neo4j (ìˆ˜ë™ ì—…ë°ì´íŠ¸, ì„ë² ë”© ê²€ìƒ‰)
    2. Google RSS (ì‹¤ì‹œê°„, ìë™ ë²ˆì—­)
    3. ê¸°ì¡´ RSS (Naver, Daum - í´ë°±ìš©)
    """
    
    def __init__(self):
        self.news_collector = NewsCollector()  # data_agentì˜ ìˆ˜ì§‘ê¸° (í´ë°±ìš©)
        self.mk_kg_service = MKKnowledgeGraphService()  # ë§¤ì¼ê²½ì œ ì§€ì‹ê·¸ë˜í”„
        self.google_translator = google_rss_translator  # Google RSS ë²ˆì—­
        self.llm = self._initialize_llm()
    
    def _initialize_llm(self):
        """LLM ì´ˆê¸°í™”"""
        if settings.google_api_key:
            return ChatGoogleGenerativeAI(
                model="gemini-2.0-flash-exp",
                temperature=0.7,
                google_api_key=settings.google_api_key,
                credentials=None  # ADC ë¹„í™œì„±í™”
            )
        return None
    
    async def get_financial_news(self, query: str) -> List[Dict[str, Any]]:
        """í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ ì¡°íšŒ (data_agentì˜ NewsCollector ì‚¬ìš©)
        
        Args:
            query: ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            List[Dict[str, Any]]: í•œêµ­ì–´ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        try:
            print(f"ğŸ“° í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê²€ìƒ‰: {query}")
            
            # data_agentì˜ NewsCollectorë¥¼ ì‚¬ìš©í•´ì„œ í•œêµ­ì–´ ë‰´ìŠ¤ ìˆ˜ì§‘
            articles = await self.news_collector.collect_news(days_back=1)
            
            # ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ê¸°ì‚¬ í•„í„°ë§
            relevant_articles = []
            for article in articles:
                # ì œëª©ì´ë‚˜ ë‚´ìš©ì— ì¿¼ë¦¬ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
                if (query.lower() in article.title.lower() or 
                    (article.content and query.lower() in article.content.lower())):
                    
                    news_item = {
                        'title': article.title,
                        'summary': article.content or '',
                        'url': article.link,
                        'published': article.published,
                        'source': 'korean_rss',
                        'is_financial': article.is_financial,
                        'topic_score': article.topic_score
                    }
                    relevant_articles.append(news_item)
            
            print(f"âœ… ê´€ë ¨ ë‰´ìŠ¤ {len(relevant_articles)}ê°œ ë°œê²¬")
            return relevant_articles[:5]  # ìµœëŒ€ 5ê°œ ë°˜í™˜
            
        except Exception as e:
            print(f"âŒ í•œêµ­ì–´ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    async def get_latest_market_news(self, limit: int = 5) -> List[Dict[str, Any]]:
        """ìµœì‹  í•œêµ­ ì‹œì¥ ë‰´ìŠ¤ ì¡°íšŒ (data_agentì˜ NewsCollector ì‚¬ìš©)
        
        Args:
            limit: ì¡°íšŒí•  ë‰´ìŠ¤ ê°œìˆ˜
            
        Returns:
            List[Dict[str, Any]]: í•œêµ­ì–´ ì‹œì¥ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        try:
            print(f"ğŸ“ˆ ìµœì‹  í•œêµ­ ì‹œì¥ ë‰´ìŠ¤ ì¡°íšŒ (ìµœëŒ€ {limit}ê°œ)")
            
            # data_agentì˜ NewsCollectorë¥¼ ì‚¬ìš©í•´ì„œ í•œêµ­ì–´ ë‰´ìŠ¤ ìˆ˜ì§‘
            articles = await self.news_collector.collect_news(days_back=1)
            
            # ì‹œì¥ ê´€ë ¨ í‚¤ì›Œë“œë¡œ í•„í„°ë§
            market_keywords = ['ì‹œì¥', 'ì£¼ì‹', 'ì¦ì‹œ', 'ì½”ìŠ¤í”¼', 'ì½”ìŠ¤ë‹¥', 'ê±°ë˜ëŸ‰', 'ìƒìŠ¹', 'í•˜ë½']
            market_articles = []
            
            for article in articles:
                # ì‹œì¥ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ë§Œ ì„ íƒ
                if any(keyword in article.title.lower() for keyword in market_keywords):
                    news_item = {
                        'title': article.title,
                        'summary': article.content or '',
                        'url': article.link,
                        'published': article.published,
                        'source': 'korean_rss',
                        'is_financial': article.is_financial,
                        'topic_score': article.topic_score
                    }
                    market_articles.append(news_item)
            
            print(f"âœ… ì‹œì¥ ë‰´ìŠ¤ {len(market_articles)}ê°œ ë°œê²¬")
            return market_articles[:limit]
            
        except Exception as e:
            print(f"âŒ ìµœì‹  ì‹œì¥ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    async def get_stock_news(self, symbol: str, limit: int = 5) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¢…ëª©ì˜ í•œêµ­ì–´ ë‰´ìŠ¤ ì¡°íšŒ (data_agentì˜ NewsCollector ì‚¬ìš©)
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼ (ì˜ˆ: "005930.KS")
            limit: ì¡°íšŒí•  ë‰´ìŠ¤ ê°œìˆ˜
            
        Returns:
            List[Dict[str, Any]]: í•œêµ­ì–´ ì¢…ëª© ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì‹¬ë³¼ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œí•˜ì—¬ ê²€ìƒ‰
            company_name = get_company_name_from_symbol(symbol)
            if not company_name:
                # ì‹¬ë³¼ì„ ì§ì ‘ ì‚¬ìš©
                company_name = symbol.replace(".KS", "")
            
            print(f"ğŸ“Š {company_name} ê´€ë ¨ í•œêµ­ì–´ ë‰´ìŠ¤ ê²€ìƒ‰")
            
            # data_agentì˜ NewsCollectorë¥¼ ì‚¬ìš©í•´ì„œ í•œêµ­ì–´ ë‰´ìŠ¤ ìˆ˜ì§‘
            articles = await self.news_collector.collect_news(days_back=3)  # 3ì¼ê°„ì˜ ë‰´ìŠ¤
            
            # í•´ë‹¹ ì¢…ëª©ê³¼ ê´€ë ¨ëœ ê¸°ì‚¬ í•„í„°ë§
            stock_articles = []
            for article in articles:
                # ì œëª©ì´ë‚˜ ë‚´ìš©ì— íšŒì‚¬ëª…ì´ í¬í•¨ëœ ê²½ìš°
                if (company_name.lower() in article.title.lower() or 
                    (article.content and company_name.lower() in article.content.lower())):
                    
                    news_item = {
                        'title': article.title,
                        'summary': article.content or '',
                        'url': article.link,
                        'published': article.published,
                        'source': 'korean_rss',
                        'is_financial': article.is_financial,
                        'topic_score': article.topic_score,
                        'symbol': symbol,
                        'company_name': company_name
                    }
                    stock_articles.append(news_item)
            
            print(f"âœ… {company_name} ê´€ë ¨ ë‰´ìŠ¤ {len(stock_articles)}ê°œ ë°œê²¬")
            return stock_articles[:limit]
            
        except Exception as e:
            print(f"âŒ ì¢…ëª© ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def generate_news_analysis(self, 
                               query: str, 
                               news_data: List[Dict[str, Any]]) -> str:
        """âœ¨ LLM ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŒ… ë‰´ìŠ¤ ë¶„ì„ (ìƒˆë¡œìš´ ë©”ì„œë“œ)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            news_data: ë‰´ìŠ¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: AI ìƒì„± ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼
        """
        if not self.llm or not news_data:
            # LLMì´ ì—†ê±°ë‚˜ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ë‹¨ìˆœ ë‚˜ì—´
            return self._format_news_simple(news_data)
        
        try:
            # âœ¨ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
            messages = prompt_manager.generate_news_prompt(
                news_data=news_data,
                user_query=query
            )
            
            # LLM í˜¸ì¶œ
            response = self.llm.invoke(messages)
            return response.content
            
        except Exception as e:
            print(f"âŒ AI ë‰´ìŠ¤ ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ë‹¨ìˆœ ë‚˜ì—´ë¡œ í´ë°±
            return self._format_news_simple(news_data)
    
    def _format_news_simple(self, news_data: List[Dict[str, Any]]) -> str:
        """ë‰´ìŠ¤ ë‹¨ìˆœ í¬ë§·íŒ… (í´ë°±ìš©)"""
        if not news_data:
            return "ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        result = f"ğŸ“° ì´ {len(news_data)}ê°œì˜ ë‰´ìŠ¤:\n\n"
        for i, news in enumerate(news_data, 1):
            result += f"{i}. {news['title']}\n"
            result += f"   {news.get('summary', '')[:100]}...\n"
            result += f"   ğŸ”— {news['url']}\n\n"
        
        return result
    
    async def get_mk_news_with_embedding(self, query: str, category: str = None, limit: int = 5) -> List[Dict[str, Any]]:
        """âœ¨ ë§¤ì¼ê²½ì œ ì§€ì‹ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë¶„ì„/íŒë‹¨ìš©)
        
        âš ï¸ ìš©ë„: ë‰´ìŠ¤ ìš”ì²­ì´ ì•„ë‹Œ, ë¶„ì„/íŒë‹¨ ì‹œ ì»¨í…ìŠ¤íŠ¸ë¡œë§Œ ì‚¬ìš©
        
        ì‚¬ìš© ì‚¬ë¡€:
        - "ì‚¼ì„±ì „ì íˆ¬ì ë¶„ì„í•´ì¤˜" â†’ ë§¤ì¼ê²½ì œ KGì—ì„œ ê´€ë ¨ ê¸°ì‚¬ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
        - "ìµœê·¼ ë°˜ë„ì²´ ì‹œì¥ ì „ë§ì€?" â†’ ë§¤ì¼ê²½ì œ KGì—ì„œ ë°°ê²½ ì§€ì‹ ì œê³µ
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            category: ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ (economy, politics, securities, international, headlines)
            limit: ë°˜í™˜í•  ë‰´ìŠ¤ ê°œìˆ˜
            
        Returns:
            List[Dict[str, Any]]: ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ (ë¶„ì„ìš©)
        """
        try:
            print(f"ğŸ“š ë§¤ì¼ê²½ì œ KG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë¶„ì„ìš©): {query}")
            
            # ë§¤ì¼ê²½ì œ ì§€ì‹ê·¸ë˜í”„ì—ì„œ ê²€ìƒ‰
            mk_results = await self.mk_kg_service.search_news(query, category, limit)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            for article in mk_results:
                news_item = {
                    'title': article['title'],
                    'summary': article['summary'] or '',
                    'content': article.get('content', ''),  # ë¶„ì„ìš© ì „ì²´ ë‚´ìš©
                    'url': article['link'],
                    'published': article['published'],
                    'source': 'mk_knowledge_graph',
                    'category': article['category'],
                    'similarity_score': article['similarity'],
                    'is_financial': self._is_financial_content(article['title']),
                    'topic_score': article['similarity']
                }
                formatted_results.append(news_item)
            
            print(f"âœ… ë§¤ì¼ê²½ì œ KG ì»¨í…ìŠ¤íŠ¸ {len(formatted_results)}ê°œ ë°œê²¬ (ë¶„ì„ìš©)")
            return formatted_results
            
        except Exception as e:
            print(f"âŒ ë§¤ì¼ê²½ì œ KG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    async def get_analysis_context_from_kg(self, query: str, limit: int = 3) -> str:
        """ë¶„ì„/íŒë‹¨ì„ ìœ„í•œ ë§¤ì¼ê²½ì œ ì§€ì‹ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        
        âš ï¸ ìš©ë„: ë‰´ìŠ¤ê°€ ì•„ë‹Œ, ë¶„ì„ ì‹œ ë°°ê²½ ì§€ì‹ ì œê³µ (KG ì—­í• )
        âœ¨ FallbackAgent ì‚¬ìš©
        
        Args:
            query: ë¶„ì„ ëŒ€ìƒ ì¿¼ë¦¬ (í•œêµ­ì–´)
            limit: ì°¸ê³ í•  ê¸°ì‚¬ ê°œìˆ˜
            
        Returns:
            str: LLMì— ì œê³µí•  ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        try:
            from app.services.langgraph_enhanced.agents import get_news_source_fallback
            
            print(f"ğŸ“š ë§¤ì¼ê²½ì œ KG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë¶„ì„ìš©, FallbackAgent): {query}")
            
            # FallbackAgentë¥¼ í†µí•œ ìë™ í’€ë°± ì‹¤í–‰
            fallback_helper = get_news_source_fallback()
            context = await fallback_helper.get_kg_context_with_fallback(query, limit)
            
            return context
            
        except Exception as e:
            print(f"âŒ ë§¤ì¼ê²½ì œ KG ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _is_financial_content(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ ê¸ˆìœµ ê´€ë ¨ì¸ì§€ íŒë‹¨"""
        finance_keywords = [
            'ì£¼ì‹', 'ì¦ê¶Œ', 'ê¸ˆìœµ', 'ì€í–‰', 'íˆ¬ì', 'ê²½ì œ', 'ì‹œì¥', 'ì£¼ê°€',
            'PER', 'PBR', 'ë°°ë‹¹', 'ìƒì¥', 'IPO', 'M&A', 'ì¸ìˆ˜', 'í•©ë³‘',
            'ê¸°ì¤€ê¸ˆë¦¬', 'ì¸í”Œë ˆì´ì…˜', 'GDP', 'í™˜ìœ¨', 'ë‹¬ëŸ¬', 'ì—”í™”',
            'ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'LGì „ì', 'í˜„ëŒ€ì°¨', 'ê¸°ì•„',
            'ìƒìŠ¹', 'í•˜ë½', 'ê¸‰ë“±', 'ê¸‰ë½', 'ê±°ë˜ëŸ‰', 'ì‹œê°€ì´ì•¡'
        ]
        
        text_lower = text.lower()
        return any(keyword in text_lower for keyword in finance_keywords)
    
    async def get_today_market_news(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ì˜¤ëŠ˜ í•˜ë£¨ì˜ ì‹œì¥ ë‰´ìŠ¤ ì¢…í•© ë¶„ì„ìš©
        
        Args:
            limit: ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜
            
        Returns:
            List[Dict[str, Any]]: ì˜¤ëŠ˜ì˜ ì£¼ìš” ì‹œì¥ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        try:
            print(f"ğŸ“ˆ ì˜¤ëŠ˜ í•˜ë£¨ ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘ ({limit}ê°œ)")
            
            # ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
            market_keywords = [
                "stock market", "korean market", "KOSPI", "KOSDAQ",
                "economy", "finance", "investment", "trading",
                "Samsung", "LG", "SK", "Hyundai", "KIA",
                "semiconductor", "AI", "technology"
            ]
            
            all_news = []
            for keyword in market_keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                try:
                    keyword_news = await search_google_news(keyword, limit=3)
                    all_news.extend(keyword_news)
                    if len(all_news) >= limit:
                        break
                except Exception as e:
                    print(f"   âš ï¸ í‚¤ì›Œë“œ '{keyword}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            unique_news = self._remove_duplicates(all_news)
            sorted_news = self._sort_news_by_relevance(unique_news, "ì˜¤ëŠ˜ í•˜ë£¨ ì‹œì¥ ë‰´ìŠ¤")
            
            print(f"âœ… ì˜¤ëŠ˜ í•˜ë£¨ ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(sorted_news)}ê°œ")
            return sorted_news[:limit]
            
        except Exception as e:
            print(f"âŒ ì˜¤ëŠ˜ í•˜ë£¨ ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    async def get_comprehensive_news(self, 
                                    query: str, 
                                    use_google_rss: bool = True,
                                    translate: bool = True,
                                    korean_query: str = None) -> List[Dict[str, Any]]:
        """âœ¨ ì¢…í•© ë‰´ìŠ¤ ê²€ìƒ‰ (ë§¤ì¼ê²½ì œ RSS + Google RSS)
        âœ¨ FallbackAgent ì‚¬ìš©
        
        ì „ëµ:
        - ë§¤ì¼ê²½ì œ RSS (í•œêµ­ì–´) â†’ korean_query ì‚¬ìš©
        - Google RSS (ì˜ì–´) â†’ query ì‚¬ìš©
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ì–´)
            use_google_rss: Google RSS ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€
            translate: Google RSS ë‰´ìŠ¤ ë²ˆì—­ ì—¬ë¶€
            korean_query: í•œêµ­ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ (ë§¤ì¼ê²½ì œìš©)
            
        Returns:
            List[Dict[str, Any]]: í†µí•©ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        try:
            from app.services.langgraph_enhanced.agents import get_news_source_fallback
            
            print(f"ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê²€ìƒ‰ (FallbackAgent): {query}")
            
            all_news = []
            
            # íŠ¹ë³„í•œ ì¼€ì´ìŠ¤: ì˜¤ëŠ˜ í•˜ë£¨ ì‹œì¥ ë‰´ìŠ¤ ìš”ì²­
            if query == "ì˜¤ëŠ˜ í•˜ë£¨ ì‹œì¥ ë‰´ìŠ¤":
                return await self.get_today_market_news(limit=10)
            
            # FallbackAgentë¥¼ í†µí•œ ìë™ í’€ë°± ì‹¤í–‰
            fallback_helper = get_news_source_fallback()
            
            # Primary ì†ŒìŠ¤ ê²°ì •
            primary_source = "google_rss" if use_google_rss else "mk_rss"
            
            # ë‰´ìŠ¤ ìˆ˜ì§‘ with ìë™ í’€ë°±
            result = await fallback_helper.get_news_with_fallback(
                query=query,
                primary_source=primary_source,
                limit=5
            )
            
            if result['success']:
                all_news = result['data']
                print(f"  âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ì„±ê³µ (ì†ŒìŠ¤: {result['source']}): {len(all_news)}ê°œ")
            else:
                print(f"  âš ï¸ ëª¨ë“  ë‰´ìŠ¤ ì†ŒìŠ¤ ì‹¤íŒ¨")
                all_news = []
            
            # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€ + ì œëª© ìœ ì‚¬ë„)
            unique_news = self._remove_duplicates(all_news)
            
            # ê´€ë ¨ë„ + ìµœì‹ ìˆœ ì •ë ¬
            sorted_news = self._sort_news_by_relevance(unique_news, query)
            
            print(f"âœ… ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼: {len(sorted_news)}ê°œ (ì¤‘ë³µ ì œê±° í›„)")
            return sorted_news[:10]  # ìµœëŒ€ 10ê°œ ë°˜í™˜
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _remove_duplicates(self, news_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ë‰´ìŠ¤ ì œê±° (URL + ì œëª© ìœ ì‚¬ë„ ê¸°ë°˜)"""
        seen_urls = set()
        seen_titles = []
        unique_news = []
        
        for news in news_list:
            url = news.get('url', '')
            title = news.get('title', '')
            
            # URL ì¤‘ë³µ ì²´í¬
            if url and url in seen_urls:
                continue
            
            # ì œëª© ìœ ì‚¬ë„ ì²´í¬ (ê°„ë‹¨í•œ ë°©ë²•)
            is_duplicate = False
            for seen_title in seen_titles:
                if self._calculate_title_similarity(title, seen_title) > 0.9:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                seen_urls.add(url)
                seen_titles.append(title)
                unique_news.append(news)
        
        return unique_news
    
    def _calculate_title_similarity(self, title1: str, title2: str) -> float:
        """ì œëª© ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ Jaccard ìœ ì‚¬ë„)"""
        if not title1 or not title2:
            return 0.0
        
        # ë‹¨ì–´ ì§‘í•©ìœ¼ë¡œ ë³€í™˜
        words1 = set(title1.lower().split())
        words2 = set(title2.lower().split())
        
        # Jaccard ìœ ì‚¬ë„
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return intersection / union if union > 0 else 0.0
    
    def _sort_news_by_relevance(self, 
                                news_list: List[Dict[str, Any]], 
                                query: str) -> List[Dict[str, Any]]:
        """ë‰´ìŠ¤ë¥¼ ê´€ë ¨ë„ + ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬"""
        import datetime
        
        def calculate_score(news: Dict[str, Any]) -> float:
            """ë‰´ìŠ¤ ì ìˆ˜ ê³„ì‚°"""
            score = 0.0
            
            # 1. ê´€ë ¨ë„ ì ìˆ˜ (similarity_score ë˜ëŠ” topic_score)
            similarity = news.get('similarity_score', news.get('topic_score', 0.5))
            score += similarity * 0.7
            
            # 2. ìµœì‹ ì„± ì ìˆ˜ (24ì‹œê°„ ì´ë‚´ +0.3, 48ì‹œê°„ ì´ë‚´ +0.2, ê·¸ ì™¸ +0.1)
            try:
                published = news.get('published', '')
                if published:
                    pub_date = datetime.datetime.fromisoformat(published.replace('Z', '+00:00'))
                    now = datetime.datetime.now(datetime.timezone.utc)
                    hours_diff = (now - pub_date).total_seconds() / 3600
                    
                    if hours_diff < 24:
                        score += 0.3
                    elif hours_diff < 48:
                        score += 0.2
                    else:
                        score += 0.1
            except:
                score += 0.1
            
            return score
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        return sorted(news_list, key=calculate_score, reverse=True)
    
    async def update_mk_knowledge_base(self, days_back: int = 7) -> Dict[str, Any]:
        """ë§¤ì¼ê²½ì œ ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸"""
        try:
            print(f"ğŸ”„ ë§¤ì¼ê²½ì œ ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì‹œì‘ (ìµœê·¼ {days_back}ì¼)")
            
            result = await self.mk_kg_service.update_knowledge_graph(days_back)
            
            if result.get('status') == 'success':
                print(f"âœ… ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {result['articles_collected']}ê°œ ê¸°ì‚¬")
            else:
                print(f"âŒ ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
            return result
            
        except Exception as e:
            print(f"âŒ ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"status": "error", "error": str(e)}


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
news_service = NewsService()
